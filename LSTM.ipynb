{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from collections import Counter\n",
    "import os\n",
    "import import_ipynb\n",
    "import getEmbeddings2\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot.plotters as skplt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 5000\n",
    "epoch_num = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cmat(yte, ypred):\n",
    "    '''Plotting confusion matrix'''\n",
    "    skplt.plot_confusion_matrix(yte, ypred)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./xtr_shuffled.npy') or \\\n",
    "    not os.path.isfile('./xte_shuffled.npy') or \\\n",
    "    not os.path.isfile('./ytr_shuffled.npy') or \\\n",
    "    not os.path.isfile('./yte_shuffled.npy'):\n",
    "    getEmbeddings2.clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr = np.load('./xtr_shuffled.npy' , allow_pickle=True)\n",
    "xte = np.load('./xte_shuffled.npy' , allow_pickle=True)\n",
    "y_train = np.load('./ytr_shuffled.npy' , allow_pickle=True)\n",
    "y_test = np.load('./yte_shuffled.npy' , allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = Counter()\n",
    "x_train = []\n",
    "for x in xtr:\n",
    "    x_train.append(x.split())\n",
    "    for word in x_train[-1]:\n",
    "        cnt[word] += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing most common words\n",
    "most_common = cnt.most_common(top_words + 1)\n",
    "word_bank = {}\n",
    "id_num = 1\n",
    "for word, freq in most_common:\n",
    "    word_bank[word] = id_num\n",
    "    id_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentences\n",
    "for news in x_train:\n",
    "    i = 0\n",
    "    while i < len(news):\n",
    "        if news[i] in word_bank:\n",
    "            news[i] = word_bank[news[i]]\n",
    "            i += 1\n",
    "        else:\n",
    "            del news[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(y_train)\n",
    "y_test = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the short news\n",
    "i = 0\n",
    "while i < len(x_train):\n",
    "    if len(x_train[i]) > 10:\n",
    "        i += 1\n",
    "    else:\n",
    "        del x_train[i]\n",
    "        del y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating test data\n",
    "x_test = []\n",
    "for x in xte:\n",
    "    x_test.append(x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentences\n",
    "for news in x_test:\n",
    "    i = 0\n",
    "    while i < len(news):\n",
    "        if news[i] in word_bank:\n",
    "            news[i] = word_bank[news[i]]\n",
    "            i += 1\n",
    "        else:\n",
    "            del news[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(x_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words+2, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epoch_num, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy= %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the confusion matrix\n",
    "y_pred = model.predict_classes(X_test)\n",
    "plot_cmat(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}